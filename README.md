# MSc_Dissertation_Modelling_chaotic_dynamical_systems
In this thesis, deterministic and probabilistic surrogate machine learning models for chaotic dynamical systems are constructed and evaluated. The chaotic systems examined are the Lorenz 63 and Lorenz 96 toy model systems. We will primarily construct Markovian or ‘memoryless’ deterministic and probabilistic surrogate models. The first systems we attempt to model are ‘fully observed’, in the sense that they rely on a full description of the system dynamics. Here, we find that both the deterministic and probabilistic surrogate models perform equally well. Then, Markovian deterministic and probabilistic surrogate models for ‘partially observed’ chaotic sys-tems are constructed, which rely on some reduced-order description of the dynamics. The story here is quite different. When the scale separation between the observed and unobserved vari-ables in the system is large, both deterministic and probabilistic Markovian models perform well. However, as the scale separation is decreased, the models tend to perform less well. That said, the deterioration in model performance with decreasing scale separation is much more severe for the deterministic models than it is for the probabilistic models. Thus, while deter-ministic models struggle to represent the statistics of a partially observed system where the effects of unobserved dynamics are significant, the probabilistic models perform adequately well. In other words, the stochastic nature of the probabilistic models can represent the unknown effects which the dynamics of the unobserved component of the system have on the observed component. That said, even though the probabilistic models perform substantially better than the deterministic models, they do not perform perfectly. In an attempt to improve upon these results, and motivated by ideas from Takens’ embedding theorem, delay-embedded deterministic and probabilistic models are constructed which use the past and present states to predict the future state. While these delay-embedded models perform better than their Markovian counter-parts in some respects, we find that constructing accurate delay-embedded models is non-trivial task. As these models work in a substantially larger input-space, consisting of past and present states of the system, finding the weights which minimize the loss function of the model becomes a more complex optimization problem. This added complexity in the optimization of the loss function leads to instability in the model results.
